import tempfile
import anthropic
import instructor

from pydantic import BaseModel, Field
from smolagents import Tool
from diffusion_studio import DiffusionClient
from typing import Any, List, Optional
from loguru import logger

MAX_IMAGES_PER_BATCH = 100


class FrameAnalysis(BaseModel):
    composition_issues: Optional[List[str]] = Field(
        default_factory=list, description="List of detected composition issues if any"
    )
    render_decision: bool = Field(
        ..., description="Whether the frames match the user requirements"
    )


class VisualFeedbackTool(Tool):
    name = "visual_feedback"
    description = """
    Analyzes video composition quality and makes render decisions taking into account the composition goal.
    Works in conjunction with VideoEditorTool to validate edits before rendering. Can point out issues with the video composition,
    which need to be fixed before rendering by the VideoEditorTool.
    """

    inputs = {
        "final_goal": {
            "type": "string",
            "description": "Quality criteria to evaluate (e.g. 'Ensure clip position are correct', 'Check for visual artifacts')",
            "nullable": False,
            "required": True,
        },
    }
    output_type = "object"

    def __init__(self, client: DiffusionClient):
        super().__init__()
        # Use sync client
        base_client = anthropic.Anthropic()
        self.anthropic_client = instructor.from_anthropic(base_client)
        self.model = "claude-3-5-sonnet-latest"
        self.client = client
        self.temp_dir = tempfile.mkdtemp()

    def forward(
        self,
        final_goal: str = "The video should show a smooth transition between scenes without any glitches or artifacts.",
    ) -> Any:
        """Process video frames and get feedback."""
        samples = sorted(self.client.samples)

        logger.info(f"Processing {len(samples)} frames with goal: {final_goal}")

        prompt = f"""Analyze the samples if they match the user composition goal: "{final_goal}".
        These samples were generated by a video editing engine, used to manipulate the videos and add motion graphics/effects/transitions etc.
        Point out any issues with the video composition, which need to be fixed before rendering related to the features of the engine.
        Do not make an assessment of materials provided by the user, e.g. video clips, images, etc.
        When everything is ok, return "Video is ready to be rendered".
        """

        try:
            all_issues = []
            is_ok_overall = True
            total_frames = len(samples)
            batch_size = min(MAX_IMAGES_PER_BATCH, total_frames)

            for batch_start in range(0, total_frames, batch_size):
                batch = samples[batch_start : batch_start + batch_size]

                message_content = []
                for i, sample in enumerate(batch, 1):
                    message_content.extend(
                        [
                            {"type": "text", "text": f"Sample {batch_start + i}:"},
                            {
                                "type": "image",
                                "source": {
                                    "type": "base64",
                                    "media_type": "image/jpeg",
                                    "data": sample,
                                },
                            },
                        ]
                    )

                message_content.append({"type": "text", "text": prompt})
                logger.info(f"Processing batch of {len(batch)} frames")

                batch_analysis = self.anthropic_client.messages.create(
                    model=self.model,
                    max_tokens=1024,
                    messages=[{"role": "user", "content": message_content}],
                    response_model=FrameAnalysis,
                )

                logger.debug(f"Batch analysis: {batch_analysis}")

                if batch_analysis.composition_issues:
                    all_issues.extend(batch_analysis.composition_issues)
                is_ok_overall = is_ok_overall and batch_analysis.render_decision

                logger.debug(f"is_ok_overall: {is_ok_overall}")

            return f'{all_issues}; Render decision: {is_ok_overall}'

        except Exception as e:
            logger.error(f"Error processing frames: {str(e)}")
            return f'{str(e)}; Render decision: False'


# if __name__ == "__main__":
#     client = DiffusionClient()

#     core_tool = VideoEditorTool(client=client)
#     visual_feedback_tool = VisualFeedbackTool(client=client)

#     # Step 1: Composition
#     logger.info("üé¨  Composing video...")
#     core_tool.forward(
#         assets=["assets/big_buck_bunny_1080p_30fps.mp4"],
#         js_code="""
#         // Create a 150 frames subclip
#         const videoFile = assets()[0];
#         const video = new core.VideoClip(videoFile).subclip(0, 150);
#         await composition.add(video);
#         """,
#         ready_to_render=False,  # Initial composition, will auto-append sample()
#     )

#     # Step 2: Analysis
#     logger.info("üîç Analyzing composition...")
#     decision = visual_feedback_tool.forward(
#         final_goal="""Analyze the video composition focusing on:
#         1. Overall flow and pacing between scenes
#         2. Visual consistency and quality
#         3. Transition opportunities and potential issues

#         Minor imperfections are acceptable if they don't impact the viewing experience.
#         Focus on issues that would be noticeable to the average viewer."""
#     )

#     logger.info(f"Decision: {decision}")
